"""
Module de screening des actions du S&P 500
Analyse et recommande des actions basÃ©es sur l'apprentissage automatique
"""

import pandas as pd
import yfinance as yf
import numpy as np
from datetime import datetime, timedelta
import logging
from typing import List, Dict, Any, Optional, Tuple

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class StockScreener:
    """
    Classe pour le screening d'actions du S&P 500
    """
    
    def __init__(self, 
                 lookback_years: int = 5,
                 test_size: float = 0.2,
                 random_state: int = 42):
        """
        Initialise le screener
        
        Args:
            lookback_years: Nombre d'annÃ©es de donnÃ©es historiques
            test_size: Proportion des donnÃ©es pour le test
            random_state: Seed pour la reproductibilitÃ©
        """
        self.lookback_years = lookback_years
        self.test_size = test_size
        self.random_state = random_state
        self.model = None
        self.scaler = StandardScaler()
        self.features = None
        self.labels = None
        self.accuracy = None
        self.screened_stocks = []
        
        logger.info(f"StockScreener initialisÃ© (lookback: {lookback_years} ans)")
    
    @staticmethod
    def get_sp500_symbols() -> List[str]:
        """
        RÃ©cupÃ¨re la liste des symboles du S&P 500 depuis Wikipedia
        """
        try:
            sp500_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
            sp500_table = pd.read_html(sp500_url)[0]
            symbols = sp500_table['Symbol'].tolist()
            
            # Nettoyer les symboles
            symbols = [str(symbol).replace('.', '-') for symbol in symbols]
            
            logger.info(f"RÃ©cupÃ©rÃ© {len(symbols)} symboles du S&P 500")
            return symbols
            
        except Exception as e:
            logger.error(f"Erreur rÃ©cupÃ©ration S&P 500: {e}")
            # Liste de secours
            return ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'NVDA', 'BRK-B', 'JPM', 'V']
    
    def fetch_stock_data(self, 
                         symbols: List[str] = None,
                         max_symbols: int = 100) -> Dict[str, pd.DataFrame]:
        """
        RÃ©cupÃ¨re les donnÃ©es historiques pour les symboles
        
        Args:
            symbols: Liste des symboles Ã  analyser
            max_symbols: Nombre maximum de symboles Ã  traiter
        """
        if symbols is None:
            symbols = self.get_sp500_symbols()
        
        # Limiter le nombre de symboles pour Ã©viter les timeouts
        symbols = symbols[:max_symbols]
        
        data = {}
        period = f"{self.lookback_years}y"
        
        logger.info(f"RÃ©cupÃ©ration des donnÃ©es pour {len(symbols)} symboles...")
        
        for i, symbol in enumerate(symbols, 1):
            try:
                if i % 10 == 0:
                    logger.info(f"  Progression: {i}/{len(symbols)}")
                
                stock = yf.Ticker(symbol)
                history = stock.history(period=period, interval='1d')
                
                if not history.empty and len(history) > 200:  # Au moins 200 jours de donnÃ©es
                    data[symbol] = history
                    
            except Exception as e:
                logger.warning(f"Erreur pour {symbol}: {e}")
                continue
        
        logger.info(f"DonnÃ©es rÃ©cupÃ©rÃ©es pour {len(data)} symboles")
        return data
    
    def calculate_features(self, data: Dict[str, pd.DataFrame]) -> Tuple[pd.DataFrame, pd.Series]:
        """
        Calcule les features pour l'entraÃ®nement du modÃ¨le
        """
        features_list = []
        labels_list = []
        
        for symbol, df in data.items():
            try:
                if len(df) < 50:  # Pas assez de donnÃ©es pour calculer SMA50
                    continue
                
                # Features de base
                df = df.copy()
                df['Returns'] = df['Close'].pct_change()
                df['SMA_20'] = df['Close'].rolling(window=20).mean()
                df['SMA_50'] = df['Close'].rolling(window=50).mean()
                df['SMA_200'] = df['Close'].rolling(window=200).mean()
                df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
                
                # Indicateurs avancÃ©s
                df['RSI'] = self._calculate_rsi(df['Close'])
                df['MACD'] = self._calculate_macd(df['Close'])
                df['Volatility'] = df['Returns'].rolling(window=20).std()
                df['Momentum'] = df['Close'] / df['Close'].shift(20) - 1
                
                # Target: Le prix montera-t-il demain ? (1 = oui, 0 = non)
                df['Target'] = (df['Close'].shift(-1) > df['Close']).astype(int)
                
                # Supprimer les NaN
                df_clean = df.dropna()
                
                if len(df_clean) > 0:
                    # Features sÃ©lectionnÃ©es
                    feature_cols = [
                        'SMA_20', 'SMA_50', 'SMA_200',
                        'Volume', 'Volume_SMA',
                        'RSI', 'MACD', 'Volatility', 'Momentum'
                    ]
                    
                    # VÃ©rifier que toutes les colonnes existent
                    available_cols = [col for col in feature_cols if col in df_clean.columns]
                    
                    if available_cols:
                        features_list.append(df_clean[available_cols])
                        labels_list.append(df_clean['Target'])
                        
            except Exception as e:
                logger.warning(f"Erreur calcul features pour {symbol}: {e}")
                continue
        
        if not features_list:
            raise ValueError("Aucune feature calculÃ©e")
        
        # ConcatÃ©ner toutes les donnÃ©es
        features = pd.concat(features_list)
        labels = pd.concat(labels_list)
        
        # VÃ©rifier l'alignement
        if len(features) != len(labels):
            raise ValueError(f"IncohÃ©rence features/labels: {len(features)} vs {len(labels)}")
        
        self.features = features
        self.labels = labels
        
        logger.info(f"Features calculÃ©es: {features.shape}")
        return features, labels
    
    def _calculate_rsi(self, prices: pd.Series, period: int = 14) -> pd.Series:
        """Calcule le RSI"""
        delta = prices.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    def _calculate_macd(self, prices: pd.Series) -> pd.Series:
        """Calcule le MACD"""
        exp1 = prices.ewm(span=12, adjust=False).mean()
        exp2 = prices.ewm(span=26, adjust=False).mean()
        macd = exp1 - exp2
        return macd
    
    def train_model(self, 
                   model_type: str = 'random_forest',
                   n_estimators: int = 100) -> Dict[str, Any]:
        """
        EntraÃ®ne le modÃ¨le de classification
        
        Args:
            model_type: Type de modÃ¨le ('random_forest', 'gradient_boosting')
            n_estimators: Nombre d'estimateurs pour les modÃ¨les d'ensemble
        """
        if self.features is None or self.labels is None:
            raise ValueError("Features ou labels non disponibles. ExÃ©cutez calculate_features d'abord.")
        
        logger.info(f"EntraÃ®nement du modÃ¨le {model_type}...")
        
        # SÃ©lection du modÃ¨le
        if model_type == 'random_forest':
            model = RandomForestClassifier(
                n_estimators=n_estimators,
                random_state=self.random_state,
                n_jobs=-1
            )
        elif model_type == 'gradient_boosting':
            model = GradientBoostingClassifier(
                n_estimators=n_estimators,
                random_state=self.random_state
            )
        else:
            raise ValueError(f"Type de modÃ¨le inconnu: {model_type}")
        
        # Pipeline avec scaling
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('classifier', model)
        ])
        
        # Split train/test
        X_train, X_test, y_train, y_test = train_test_split(
            self.features, self.labels,
            test_size=self.test_size,
            random_state=self.random_state,
            shuffle=False  # Garder l'ordre temporel
        )
        
        # EntraÃ®nement
        pipeline.fit(X_train, y_train)
        
        # Ã‰valuation
        y_pred = pipeline.predict(X_test)
        
        # MÃ©triques
        metrics = {
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1_score': f1_score(y_test, y_pred, zero_division=0),
            'model_type': model_type,
            'train_samples': len(X_train),
            'test_samples': len(X_test)
        }
        
        # Validation croisÃ©e
        cv_scores = cross_val_score(pipeline, self.features, self.labels, cv=5)
        metrics['cv_mean_accuracy'] = cv_scores.mean()
        metrics['cv_std_accuracy'] = cv_scores.std()
        
        self.model = pipeline
        self.accuracy = metrics['accuracy']
        
        logger.info(f"ModÃ¨le entraÃ®nÃ© - Accuracy: {metrics['accuracy']:.3f}")
        logger.info(f"PrÃ©cision: {metrics['precision']:.3f}, Recall: {metrics['recall']:.3f}")
        
        return metrics
    
    def screen_stocks(self, 
                     data: Dict[str, pd.DataFrame],
                     min_probability: float = 0.6,
                     max_stocks: int = 20) -> List[Dict[str, Any]]:
        """
        Screen les stocks basÃ©s sur le modÃ¨le entraÃ®nÃ©
        
        Args:
            data: Dictionnaire des donnÃ©es historiques
            min_probability: ProbabilitÃ© minimale pour recommander l'achat
            max_stocks: Nombre maximum de stocks Ã  recommander
        """
        if self.model is None:
            raise ValueError("ModÃ¨le non entraÃ®nÃ©. ExÃ©cutez train_model d'abord.")
        
        logger.info(f"Screening des stocks (min_probability: {min_probability})...")
        
        recommended_stocks = []
        
        for symbol, df in data.items():
            try:
                # Calculer les features pour la derniÃ¨re ligne
                last_row = self._prepare_stock_features(df)
                
                if last_row is not None and len(last_row) > 0:
                    # PrÃ©diction
                    proba = self.model.predict_proba([last_row])[0]
                    buy_probability = proba[1]  # ProbabilitÃ© de classe positive (achat)
                    
                    # Informations sur le stock
                    current_price = df['Close'].iloc[-1]
                    volume = df['Volume'].iloc[-1]
                    sma_50 = df['Close'].rolling(50).mean().iloc[-1] if len(df) >= 50 else None
                    
                    # RSI
                    rsi = self._calculate_rsi(df['Close']).iloc[-1] if len(df) >= 15 else None
                    
                    # Recommander si probabilitÃ© suffisante
                    if buy_probability >= min_probability:
                        stock_info = {
                            'symbol': symbol,
                            'current_price': float(current_price),
                            'buy_probability': float(buy_probability),
                            'volume': int(volume),
                            'sma_50': float(sma_50) if sma_50 else None,
                            'rsi': float(rsi) if rsi else None,
                            'price_vs_sma50': float((current_price - sma_50) / sma_50 * 100) if sma_50 else None,
                            'signal_strength': 'FORT' if buy_probability >= 0.8 else 'MOYEN' if buy_probability >= 0.6 else 'FAIBLE'
                        }
                        recommended_stocks.append(stock_info)
                        
            except Exception as e:
                logger.warning(f"Erreur screening {symbol}: {e}")
                continue
        
        # Trier par probabilitÃ© dÃ©croissante
        recommended_stocks.sort(key=lambda x: x['buy_probability'], reverse=True)
        
        # Limiter le nombre de rÃ©sultats
        recommended_stocks = recommended_stocks[:max_stocks]
        
        self.screened_stocks = recommended_stocks
        
        logger.info(f"{len(recommended_stocks)} stocks recommandÃ©s pour achat")
        return recommended_stocks
    
    def _prepare_stock_features(self, df: pd.DataFrame) -> Optional[np.ndarray]:
        """PrÃ©pare les features d'un stock pour la prÃ©diction"""
        try:
            if len(df) < 50:
                return None
            
            df = df.copy()
            
            # Calculer les mÃªmes features que pendant l'entraÃ®nement
            df['SMA_20'] = df['Close'].rolling(window=20).mean()
            df['SMA_50'] = df['Close'].rolling(window=50).mean()
            df['SMA_200'] = df['Close'].rolling(window=200).mean()
            df['Volume_SMA'] = df['Volume'].rolling(window=20).mean()
            df['RSI'] = self._calculate_rsi(df['Close'])
            df['MACD'] = self._calculate_macd(df['Close'])
            df['Returns'] = df['Close'].pct_change()
            df['Volatility'] = df['Returns'].rolling(window=20).std()
            df['Momentum'] = df['Close'] / df['Close'].shift(20) - 1
            
            # Prendre la derniÃ¨re ligne
            last_row = df.iloc[-1]
            
            # SÃ©lectionner les mÃªmes features que pendant l'entraÃ®nement
            feature_cols = [
                'SMA_20', 'SMA_50', 'SMA_200',
                'Volume', 'Volume_SMA',
                'RSI', 'MACD', 'Volatility', 'Momentum'
            ]
            
            available_cols = [col for col in feature_cols if col in last_row.index]
            
            if available_cols:
                return last_row[available_cols].values.astype(float)
            else:
                return None
                
        except Exception as e:
            logger.warning(f"Erreur prÃ©paration features: {e}")
            return None
    
    def save_results(self, 
                    recommended_stocks: List[Dict[str, Any]],
                    output_file: str = 'screened_stocks.csv'):
        """Sauvegarde les rÃ©sultats du screening"""
        try:
            if not recommended_stocks:
                logger.warning("Aucun stock Ã  sauvegarder")
                return
            
            df = pd.DataFrame(recommended_stocks)
            
            # Ajouter des colonnes supplÃ©mentaires
            df['screening_date'] = datetime.now().strftime('%Y-%m-%d')
            df['model_accuracy'] = self.accuracy
            
            # RÃ©organiser les colonnes
            cols = ['symbol', 'current_price', 'buy_probability', 'signal_strength',
                   'rsi', 'price_vs_sma50', 'volume', 'screening_date', 'model_accuracy']
            df = df[[c for c in cols if c in df.columns]]
            
            # Sauvegarder
            df.to_csv(output_file, index=False, encoding='utf-8')
            logger.info(f"RÃ©sultats sauvegardÃ©s: {output_file} ({len(df)} stocks)")
            
            return df
            
        except Exception as e:
            logger.error(f"Erreur sauvegarde rÃ©sultats: {e}")
            return None
    
    def create_summary_report(self) -> Dict[str, Any]:
        """CrÃ©e un rapport de summary du screening"""
        report = {
            'screening_date': datetime.now().isoformat(),
            'model_accuracy': self.accuracy,
            'total_screened_stocks': len(self.screened_stocks),
            'stocks_by_signal': {},
            'average_probability': 0.0,
            'top_stocks': []
        }
        
        if self.screened_stocks:
            # Regrouper par force de signal
            for stock in self.screened_stocks:
                signal = stock['signal_strength']
                report['stocks_by_signal'][signal] = report['stocks_by_signal'].get(signal, 0) + 1
            
            # Moyenne des probabilitÃ©s
            report['average_probability'] = np.mean([s['buy_probability'] for s in self.screened_stocks])
            
            # Top 5 stocks
            report['top_stocks'] = self.screened_stocks[:5]
        
        return report


def screen_sp500(lookback_years: int = 3,
                min_probability: float = 0.65,
                max_stocks: int = 15,
                model_type: str = 'random_forest') -> Dict[str, Any]:
    """
    Fonction principale pour screen les stocks du S&P 500
    
    Returns:
        Dict avec les rÃ©sultats du screening
    """
    logger.info("ğŸ” DÃ©marrage du screening S&P 500")
    logger.info(f"ParamÃ¨tres: lookback={lookback_years} ans, min_prob={min_probability}")
    
    try:
        # Initialiser le screener
        screener = StockScreener(lookback_years=lookback_years)
        
        # RÃ©cupÃ©rer les symboles
        symbols = screener.get_sp500_symbols()
        
        # RÃ©cupÃ©rer les donnÃ©es (limitÃ© Ã  150 symboles pour la performance)
        data = screener.fetch_stock_data(symbols[:150])
        
        if not data:
            raise ValueError("Aucune donnÃ©e rÃ©cupÃ©rÃ©e")
        
        # Calculer les features
        features, labels = screener.calculate_features(data)
        
        # EntraÃ®ner le modÃ¨le
        metrics = screener.train_model(model_type=model_type)
        
        # Screen les stocks
        recommended_stocks = screener.screen_stocks(
            data=data,
            min_probability=min_probability,
            max_stocks=max_stocks
        )
        
        # Sauvegarder les rÃ©sultats
        output_file = f"screened_stocks_{datetime.now().strftime('%Y%m%d')}.csv"
        results_df = screener.save_results(recommended_stocks, output_file)
        
        # CrÃ©er le rapport
        report = screener.create_summary_report()
        report['metrics'] = metrics
        
        logger.info(f"âœ… Screening terminÃ©: {len(recommended_stocks)} stocks recommandÃ©s")
        
        return {
            'success': True,
            'report': report,
            'stocks': recommended_stocks,
            'metrics': metrics,
            'output_file': output_file
        }
        
    except Exception as e:
        logger.error(f"âŒ Erreur screening S&P 500: {e}", exc_info=True)
        return {
            'success': False,
            'error': str(e),
            'stocks': []
        }


def get_sp500_symbols() -> List[str]:
    """Fonction utilitaire pour rÃ©cupÃ©rer les symboles du S&P 500"""
    return StockScreener.get_sp500_symbols()


def main():
    """Fonction principale pour exÃ©cuter le screening en standalone"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Screening des actions du S&P 500")
    parser.add_argument("--lookback", type=int, default=3, 
                       help="AnnÃ©es de donnÃ©es historiques (dÃ©faut: 3)")
    parser.add_argument("--min-prob", type=float, default=0.65,
                       help="ProbabilitÃ© minimale pour recommandation (dÃ©faut: 0.65)")
    parser.add_argument("--max-stocks", type=int, default=15,
                       help="Nombre maximum de stocks Ã  recommander (dÃ©faut: 15)")
    parser.add_argument("--model", choices=['random_forest', 'gradient_boosting'],
                       default='random_forest', help="Type de modÃ¨le (dÃ©faut: random_forest)")
    
    args = parser.parse_args()
    
    print("ğŸš€ SCREENING S&P 500 - Analyse d'actions avec IA")
    print("=" * 60)
    
    results = screen_sp500(
        lookback_years=args.lookback,
        min_probability=args.min_prob,
        max_stocks=args.max_stocks,
        model_type=args.model
    )
    
    if results['success']:
        report = results['report']
        stocks = results['stocks']
        
        print(f"\nğŸ“Š RÃ‰SULTATS DU SCREENING:")
        print(f"   ğŸ“… Date: {report['screening_date'].split('T')[0]}")
        print(f"   ğŸ¯ PrÃ©cision du modÃ¨le: {results['metrics']['accuracy']:.3f}")
        print(f"   ğŸ“ˆ Stocks recommandÃ©s: {report['total_screened_stocks']}")
        
        if stocks:
            print(f"\nğŸ† TOP 5 ACTIONS RECOMMANDÃ‰ES:")
            for i, stock in enumerate(stocks[:5], 1):
                print(f"   {i}. {stock['symbol']}:")
                print(f"      Prix: ${stock['current_price']:.2f}")
                print(f"      ProbabilitÃ© achat: {stock['buy_probability']:.1%}")
                print(f"      Signal: {stock['signal_strength']}")
                if stock['rsi']:
                    print(f"      RSI: {stock['rsi']:.1f}")
                print()
        
        print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s: {results['output_file']}")
        print("ğŸ’¡ Conseil: Analysez ces actions avec le module principal pour plus de dÃ©tails")
    else:
        print(f"âŒ Erreur: {results['error']}")
    
    print("=" * 60)


if __name__ == "__main__":
    main()